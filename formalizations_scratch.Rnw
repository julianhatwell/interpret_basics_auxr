\documentclass{article}

\addtolength{\hoffset}{-2.25cm}
\addtolength{\textwidth}{4.5cm}
\addtolength{\voffset}{-2.5cm}
\addtolength{\textheight}{5cm}
\setlength{\parskip}{0pt}
\setlength{\parindent}{15pt}

\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[colorlinks = true, linkcolor = black, citecolor = black, final]{hyperref}

\usepackage{graphicx}
\usepackage{multicol}
\usepackage{subcaption}
\usepackage{bbm}
\usepackage{marvosym}
\usepackage{wasysym}
\usepackage{tikz}
\usetikzlibrary{patterns}

\graphicspath{ {figs/} }

\usepackage[para]{footmisc}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}
\urlstyle{same}

\newcommand{\ds}{\displaystyle}
\DeclareMathOperator{\sech}{sech}

\setlength{\parindent}{0in}
\pagestyle{empty}

% this is to allow multiple footnotes at one point with a comma separator in the superscript
% given here: https://tex.stackexchange.com/questions/28465/multiple-footnotes-at-one-point
% last solution on the page
\let\oldFootnote\footnote
\newcommand\nextToken\relax

\renewcommand\footnote[1]{%
    \oldFootnote{#1}\futurelet\nextToken\isFootnote}

\newcommand\isFootnote{%
    \ifx\footnote\nextToken\textsuperscript{,}\fi}
% end of multiple footnotes solution


\begin{document}

\thispagestyle{empty}

{\scshape J.Hatwell} \hfill {\scshape April 2018}

\begin{center}
{\scshape \large Interpretability of Ensemble Machine Learning: \\ Formalizations}
\end{center}
 
\smallskip

\hrule

\bigskip

\subsection{Formalizations}

\subsubsection{The Survey Forest Method}

This section describes methods for gathering structural statistics from a random forest using batches of data. In the inductive mode, the entire training set $\mathcal{LS}$, or a sample (without replacement) from it $\mathcal{LS}_s \subset \mathcal{LS}$, can be used. In the transductive mode, a batch of unseen data $\mathcal{TS}$ is used. This could be a held out set, or new samples where the true classes are known.

Let $\mathcal{J}$ be the set of features, where any ordinal or nominal variables having $K > 2$ have been converted to a set of binary valued variables (i.e. binary encoding or one hot encoding).

The structure of a DT can be represented as a set of vectors. Let $\overrightarrow{F}$ be the vector of positional nodes with allowed values $j \in J$, being index numbers $j$ of the features as they appears in $\textbf{X}$. Let $\overrightarrow{C_L}$ and $\overrightarrow{C_R}$ also having allowed values $j \in J$, be vectors of left and right children respectively of the features ordered in $\overrightarrow{F}$. Such that the value at $\overrightarrow{F_0}$ is the index of the feature used at the root node, the value at $\overrightarrow{{C_L}_0}$ is the index of the feature used in the left child of the root node $\overrightarrow{F_1}$ is the 



\subsubsection{The Supervized Learning Problem}
To make the case for explanations from decision tree ensembles and rule lists, it is useful to recapitulate the general problem supervised statistical learning described by \cite{vapnik_statistical_1998}, \cite{friedman_elements_2001} and others. The theory is adapted with inclusions from the random utility model (RUM), as described in \cite{croissant_estimation_2012}.\\

Let there be some data generating process $\mathcal{G}$ which generates i.i.d. vectors $v \in \mathcal{V}$ according to some fixed, unknown frequency distribution function $F(\mathcal{V})$. This distribution is unknown but could be approximated statistically, given enough instances of $v$.\\

Let some supervisor $\mathcal{S}$ act on the vectors $v \in \mathcal{V}$ to produce a result, $y \in \mathcal{Y}$, according to a fixed, unknown, conditional distribution function $F(\mathcal{Y}|\mathcal{V})$. However, only $\mathcal{X}$, a linear subspace of $\mathcal{V}$, is ever observed. The unobserved component is then $\mathcal{U} = \mathcal{V} - \mathcal{X}$.\\

From $F(\mathcal{Y}|\mathcal{V})$ there exists then a deterministic relationship. Let $g_{\mathcal{V}}(V) = E[F(\mathcal{Y}|\mathcal{V} = V)]$

\begin{flalign*}
&& Y &= g_{\mathcal{V}}(V) && \\
&& &= g_{\mathcal{V}}(X + U) &&
\end{flalign*}

Let there exist a pair of functions $f(x) + g_\mathcal{U}(u)$ such that $\forall V \subset \mathcal{V},\ \epsilon = E[g_\mathcal{U}(U)] = 0$

\begin{equation}
Y = f(X) + \epsilon
\end{equation}

$\epsilon$ now represents the impact of all the unobserved variables as a departure from a deterministic relationship between $Y$ and $X$. By putting specific assumptions and constraints on $Y$, $f(X)$ and $\epsilon$, specific statistical learning models, such as linear models, can be defined.\\ 

Given the above definitions, the operator $S$ is the target for a learning algorithm. $\mathcal{S}$ returns tuples $(X, Y)$ from vectors $V$ generated by $\mathcal{G}$ but usually only $X$ are ever observed. A sample of these observed pairs $\mathcal{TS} = (\textbf{X}, Y)$, the training set, are available where $\textbf{X}$ is an $N \times p$ matrix of observed feature variables and $Y$ is a vector of length $N$. From this training set, the learning algorithm must find an approximation $\hat{f}(x)$ that minimizes the difference between $\hat{y_i}$ and $y_i$ for unseen samples $(\textbf{X}', Y')$ which is usually achieved by minimizing the error between $\hat{y_i}$ and $y_i$ for $\mathcal{TS}$, where $\hat{y} = \hat{f}(x)$.\\

To specialize the above explanations to the binary or multi-class classification problem, let $Y$ take on one of a finite set of possible labels $k \in K,\ |K| \geq 2$. The utility of each possible choice of $y_i = k$ is the result of a set of $|K|$ functions, which can be represented as a probability mass function $F(Y = k|X)$ and the choice of $y_i = k$ is the made by maximum utility:

\begin{equation} \label{rum}
y_i = \underset{k}{\mathrm{argmax}} \{ U_{i,k} \},\ \forall{k \in K},\ U_{i,k} = F(y_i = k|x_i) + \epsilon_{i,k}
\end{equation}

While the choice of $k$ is made deterministically by $S$, learning an approximation of $F(Y= k|X)$ is non-deterministic, because $\epsilon$ is unobserved by the learning algorithm. The learning task then is  to find a function that minimizes a loss function $\textbf{L}$ defined as a $K \times K$ matrix subject to $\textit{diag}(\textbf{L}) = [0_1,\ 0_2,\ \dots,\ 0_k], \textit{diag}'(\textbf{L}) \neq 0$. Frequently, the zero-â€“one loss function, $\mathbbm{1}\{\textit{r, c}\}$, is used where $\textbf{L}$ is strictly $\textit{diag}'(\textbf{L}) = 1$ and all misclassifications are considered equal.\\

As previously stated, the learning algorithm must find an approximation $\hat{f}(x)$ that minimizes the risk, or difference between $\hat{y}$ and $y$ for unseen samples $(\textbf{X}', Y')$. This risk can now be defined as:

\begin{equation} \label{risk}
\textit{risk} = \frac{\sum^N_{i = 1}\mathbbm{1}\{\hat{Y_i} \neq Y_i\}}{N}
\end{equation}

\subsubsection{Explanations from Tree Ensembles and Rule Lists}

Let $f^\textit{tree}$ be the class of functions which return a binary decision tree on \textbf{X} and let $\hat{f}$ be constrained to be a random forest model made of $J$ instances of $\hat{f}^\textit{tree}$, such that $\hat{Y_i} = \hat{f}(\textbf{X}_i) = \underset{k}{\mathrm{argmax}} \{\sum^J_{j=1}{\mathbbm{1}\{\hat{f}^\textit{tree}_j = k\}}\}$ (the majority voted class).\\

Logical rules, are often represented in the form $A \to C$, where $A$ is the antecedent and $C$ is the consequent. Let an individual tree prediction take this form, $\hat{f}^{tree}_j(\textbf{X}_i) \to \hat{Y_i}$ then $\hat{f}(\textbf{X}_i)$ can be reduced to a single rule $\mathcal{R}_{i, j}$ which is the conjunction of all conditions resolving to true as the values of $\textbf{X}_i$ are passed down the decision nodes of $\hat{f}^{tree}$ from entry point to leaf node. Then let $\mathcal{RS}_{i,k}$ be the ruleset extracted from $\hat{f} = \forall{\mathcal{R}_{i, j}} : j \in J\ \land\ \hat{f}^{tree}_j(\textbf{X}_i) = k$\\

The rule list compression comes next, removing redundancy from $\mathcal{RS}_{i,k}$ and then looking for differences between $\mathcal{RS}_{i,k}$ for each k. The following are from \cite{lughofer_evolving_2016}: Rule distinguishability is where rules don't overlap. Highly overlapping rules result in sets that are indistinguishable. Obsolete rules add to complexity and should be removed. $\epsilon$-completeness is where for each instance, there is a rule for which the instance has minimum $\epsilon$ coverage. Conflict points appear in the spaces between well-formed clusters. Degree of conflict can be measured as similarity to each cluster over total similarity. Ignorance points are those that are outside the space defined by the training data which have to be extrapolated. Degree of ignorance is 1 - maximum participation in any rule. In a system of multiple rules, deducing the most actively firing rule will be important. Thus weighting of nodes. Local property and Addition to one unity: For each instance there should be a maximum of 2 to the p rules firing, with p the input dimensionality. Consistency - similar rules should not have different consequents.\\



 There is a lot more stuff here: \url{https://stats.stackexchange.com/questions/1194/practical-thoughts-on-explanatory-vs-predictive-modeling}


Trust is a difficult term. Why is a well performing model not also trusted? Is trust gained by understanding? Is trust based on a model working well in deployed real-world scenarios? Is it based on formal guarantees? What if a model makes mistakes but they are the same mistakes humans make? WHat if those mistakes are founded on built in bias (over-policing of ethnic minority neighbourhoods).

Supevised learning models are optimized to find useful associations, not causes. It is no longer useful to find a link between smoking and lung cancer. Finding causal relationships in observational data relies on prior knowledge (look up Judea Pearl). So an interpretable model can only hope to throw forward the possibility to identify new hypotheses, not to deliver any surety about their merit.

The asthma case, as described in Hall et al video seminar. There's also here a specific example of a financial services company that uses logistic regression, citing interpretability. These credit rating models can be easily manipulated and the companies that own them even issue guides for this expressed purpose.





\end{document}