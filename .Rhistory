, sens_results$rule.length)
comp_results$rule.length <- ifelse(comp_results$rule.length == 0
, 1
, comp_results$rule.length)
comp_results$pretty.rule[is.na(comp_results$pretty.rule)] <- "{default}"
comp_results$pretty.rule[comp_results$pretty.rule == ""] <- "{default}"
comp_results$pretty.rule[comp_results$pretty.rule == "[]"] <- "{default}"
library(dplyr)
library(tidyr)
library(ggplot2)
# fudge until added absolute coverage, train and test set sizes to results
train_set_size <- integer(length(datasetnames))
test_set_size <- integer(length(datasetnames))
for (i in seq_along(datasetnames)) {
train_set_size[i] <- get_train_test_sizes(i)[1]
test_set_size[i] <- get_train_test_sizes(i)[2]
}
names(train_set_size) <- datasetnames
names(test_set_size) <- datasetnames
laplace_corrections <- function(results_set, datasetname, sensitivity = TRUE) {
# filter all results to one dataset
analysis_out <- results_set %>%
filter(dataset == datasetname)
if (sensitivity == TRUE) {
analysis_out <- analysis_out %>% mutate(support = factor(support)
, alpha_paths = factor(alpha_paths)
, disc_path_bins = factor(disc_path_bins)
, score_func = factor(score_func)
, weighting = weighting)
}
analysis_out <- analysis_out %>% mutate(
# covered is train set size * coverage
covered.tr. = (train_set_size[datasetname] * coverage.tr.)
# covered correct is (covered + 1 (explanandum)) * stability
# , cc.tr. = (covered.tr. + 1) * stability.tr.
, cc.tr. = covered.tr. * precision.tr.
# covered incorrect is covered - cc
, ci.tr. = covered.tr. - cc.tr.
, stability.tr.lapl. = (cc.tr. + 1) / (covered.tr. + n_classes[datasetname] + 1) # laplace and stability
, xcoverage.tr.lapl. = (covered.tr. + 1) / (train_set_size[datasetname] + n_classes[datasetname] + 1) # laplace and xcoverage
, odds.tr.lapl. = (cc.tr. + 1 + 1/n_classes[datasetname])/(ci.tr. + (n_classes[datasetname] - 1) + (n_classes[datasetname] - 1)/n_classes[datasetname])
, lodds.tr.lapl. = log(odds.tr.lapl.)
# covered is test set size - 1  * coverage (because of LOO)
, covered.tt. = ((test_set_size[datasetname] - 1) * coverage.tt.)
# covered correct is (covered + 1 (explanandum)) * stability
# , cc.tt. = (covered.tt. + 1) * stability.tt.
, cc.tt. = covered.tt. * precision.tt.
# covered incorrect is covered - cc
, ci.tt. = covered.tt. - cc.tt.
, stability.tt.lapl. = (cc.tt. + 1) / (covered.tt. + n_classes[datasetname] + 1) # laplace and stability
, xcoverage.tt.lapl. = ((covered.tt. + 1) / (test_set_size[datasetname] + n_classes[datasetname] + 1)) * # laplace and xcoverage
( ci.tt. / (ci.tt. + (test_set_size[datasetname] - covered.tt.)))
, odds.tt.lapl. = (cc.tt. + 1 + 1/n_classes[datasetname])/(ci.tt. + (n_classes[datasetname] - 1) + (n_classes[datasetname] - 1)/n_classes[datasetname])
, lodds.tt.lapl. = log(odds.tt.lapl.))
return(analysis_out)
}
get_CHIRPS_analysis <- function(measure, results_set
, top_mean_block = NA
, top_ranksum_block = NA) {
# sensitivity analysis
analysis_out <- list()
for (ds in datasetnames) {
# results collection
analysis_out[[ds]] <- list()
# filter all results to one dataset
analysis <- laplace_corrections(results_set, ds)
# get the listing of all the sensitivity analyses by grid
analysis_groups <- with(analysis, expand.grid(
support = unique(support)
, alpha = unique(alpha_paths)
, bins = unique(disc_path_bins)
, func = unique(score_func)
, weights = unique(weighting)))
# provide id numbers
analysis_groups$id <- as.numeric(rownames(analysis_groups))
# extract the values of "measure"
analysis_values <- tapply(analysis[, measure]
, list(analysis$support
, analysis$alpha_paths
, analysis$disc_path_bins
, analysis$score_func
, analysis$weighting)
, identity)
analysis_values <- matrix(unlist(analysis_values), ncol = nrow(analysis_groups))
analysis_out[[ds]][["analysis_values"]] <- analysis_values
# get a first taste of results
analysis_groups$mean <- apply(analysis_values, 2, mean)
analysis_groups$rank_mean <- colMeans(t(apply(analysis_values, 1, rank)))
analysis_groups$rank_sum <- colSums(t(apply(analysis_values, 1, rank)))
# plot the facet, hopefully showing lack of bins effect and use of chisq
bins_plot <- ggplot(
data = analysis_groups
, aes(y = mean
, x = id
, shape = alpha
, colour = func
, size = support)) +
geom_point() +
scale_size_discrete(range = c(2, 4)) +
theme_bw() +
facet_grid(weights~bins)
# collect plot
analysis_out[[ds]][["bins_weights_facet"]] <- bins_plot
# collect groups results
analysis_out[[ds]][["analysis_groups"]] <- analysis_groups
# which is the best mean measure discover or feed in from best stability
if (is.na(top_mean_block)) {
ds_top_mean_block <- which.max(analysis_out[[ds]]$analysis_groups$mean)
} else {
ds_top_mean_block <- top_mean_block
}
analysis_out[[ds]][["top_mean_block"]] <- ds_top_mean_block
if (is.na(top_ranksum_block)) {
ds_top_ranksum_block <- which.max(analysis_out[[ds]]$analysis_groups$rank_sum)
} else {
ds_top_ranksum_block <- top_ranksum_block
}
analysis_out[[ds]][["top_ranksum_block"]] <- ds_top_ranksum_block
top_group_stats <- filter(analysis_groups, id == ds_top_ranksum_block) %>%
dplyr::select(support, alpha, bins, func, weights)
analysis_out[[ds]][["ds_bestmean_values"]] <- analysis_out[[ds]]$analysis_values[, analysis_out[[ds]][["top_mean_block"]]]
analysis_out[[ds]][["ds_bestranksum_values"]] <- analysis_out[[ds]]$analysis_values[, analysis_out[[ds]][["top_ranksum_block"]]]
sens_raw <- analysis %>% filter(support == top_group_stats$support
, alpha_paths == top_group_stats$alpha
, disc_path_bins == top_group_stats$bins
, score_func == top_group_stats$func
, weighting == top_group_stats$weights)
analysis_out[[ds]][["sens_raw"]] <- sens_raw
}
mean_all_ds <- matrix(NA
, ncol = length(datasetnames)
, nrow = ncol(analysis_out$adult_small_samp$analysis_values))
ranksum_all_ds <- matrix(NA
, ncol = length(datasetnames)
, nrow = ncol(analysis_out$adult_small_samp$analysis_values))
for (j in seq_along(datasetnames)) {
mean_all_ds[, j] <- analysis_out[[datasetnames[j]]]$analysis_groups$mean
ranksum_all_ds[, j] <- analysis_out[[datasetnames[j]]]$analysis_groups$rank_sum
}
analysis_out$overall_bestmean_block <- which.max(apply(mean_all_ds, 1, mean)) # 5
analysis_out$overall_bestranksum_block <- which.max(apply(ranksum_all_ds, 1, mean)) # 5
for (ds in datasetnames) {
analysis_out[[ds]][["overall_bestmean_values"]] <- analysis_out[[ds]]$analysis_values[, analysis_out$overall_bestmean_block]
analysis_out[[ds]][["overall_bestranksum_values"]] <- analysis_out[[ds]]$analysis_values[, analysis_out$overall_bestranksum_block]
}
return(analysis_out)
}
# comparative analysis
get_comparative_analysis <- function(measure, results_set, CHIRPS_analysis) {
for (ds in datasetnames) {
# isolate and transform for one dataset
analysis <- laplace_corrections(results_set, ds, sensitivity = FALSE)
# transpose the raw values for analysis
analysis_values <- tapply(analysis[, measure]
, analysis$algorithm
, identity)
algos <- names(analysis_values) # no brl for cardio or nursery, no lending for brl or intrees
analysis_values <- matrix(unlist(analysis_values), ncol = length(algos))
analysis_values <- cbind(analysis_values, CHIRPS_analysis[[ds]]$ds_bestranksum_values)
# collect
algos <- c(algos, "CHIRPS")
colnames(analysis_values) <- algos
CHIRPS_analysis[[ds]][["comp_raw"]] <- analysis
CHIRPS_analysis[[ds]][["comp_values"]] <- analysis_values
# friedman test
CHIRPS_analysis[[ds]][["comp_frd.tt"]] <- friedman.test(analysis_values)
chisqstat <- CHIRPS_analysis[[ds]][["comp_frd.tt"]]$statistic
df1 <- CHIRPS_analysis[[ds]][["comp_frd.tt"]]$parameter
N <- nrow(analysis_values)
fstat <- (chisqstat * (N - 1)) / (N * df1 - chisqstat)
names(fstat) <- "Friedman F"
df2 <- df1 * (N - 1)
fpvalue <- pf(fstat, df1=df1, df2=df2, lower.tail = FALSE)
# collect
CHIRPS_analysis[[ds]][["comp_frd.tt"]][["F.statistic"]] <- fstat
CHIRPS_analysis[[ds]][["comp_frd.tt"]][["F.p.value"]] <- fpvalue
CHIRPS_analysis[[ds]][["comp_frd.tt"]][["F.N"]] <- N
CHIRPS_analysis[[ds]][["comp_frd.tt"]][["F.df1"]] <- df1
CHIRPS_analysis[[ds]][["comp_frd.tt"]][["F.df2"]] <- df2
}
return(CHIRPS_analysis)
}
results_in_detail <- function(analysis_in, rounding = 2, sgn = -1) {
for (ds in datasetnames) {
print(ds)
print("mean qm")
print(round(apply(analysis_in[[ds]]$comp_values, 2, mean), rounding))
print("sd qm")
print(round(apply(analysis_in[[ds]]$comp_values, 2, sd), rounding))
print("min qm")
print(round(apply(analysis_in[[ds]]$comp_values, 2, min), rounding))
print("max qm")
print(round(apply(analysis_in[[ds]]$comp_values, 2, max), rounding))
print("med qm")
print(round(apply(analysis_in[[ds]]$comp_values, 2, median), rounding))
mr <- apply(apply(sgn * analysis_in[[ds]]$comp_values, 1, rank), 1, mean)
print("mean ranks")
print(round(mr, rounding))
print("Fried test")
fstat <- analysis_in[[ds]][["comp_frd.tt"]][["F.statistic"]]
df1 <- analysis_in[[ds]][["comp_frd.tt"]][["F.df1"]]
df2 <- analysis_in[[ds]][["comp_frd.tt"]][["F.df2"]]
N <- analysis_in[[ds]][["comp_frd.tt"]][["F.N"]]
f.p.value <- analysis_in[[ds]][["comp_frd.tt"]][["F.p.value"]]
print(c(fstat, df1, df2, N, f.p.value))
print("post hoc tests")
algs <- names(mr)[names(mr) != "CHIRPS"]
k <- analysis_in[[ds]]$comp_frd.tt$parameter + 1
md <- mr[algs] - mr["CHIRPS"]
print("rank diff")
print(round(md, rounding))
z <- (md) / sqrt((k * (k + 1)) / (6 * N))
ztest <- pnorm(z, lower.tail = FALSE)
print("z stat")
print(z)
print("post-hoc z-test")
print(ztest)
print("reject null bonferroni")
print(ztest < 0.025/df1)
print(0.025/df1)
}
}
source("C:\\Users\\id126493\\OneDrive\\Documents\\PhD\\KTheme.R")
reds <- k.grad.red.rev(2)
ongs <- k.grad.orange.rev(2)
blus <- k.grad.blue.rev(2)
grns <- k.grad.green.rev(2)
prps <- k.grad.purple.rev(2)
nuts <- myPalNeut
algs <- c(algorithms, "CHIRPS")
myPal <- c(reds[2], ongs[2], blus[2], grns[2], k.pink)
myAlph <- c(rep(0.4, length(algs) - 1), 1)
names(myPal) <- algs
names(myAlph) <- algs
colos <- scale_colour_manual(
values = myPal)
alpas <- scale_alpha_manual(values = myAlph)
results_in_plots <- function(analysis_in, rounding = 2, sgn = -1) {
nds <- length(datasetnames)
dmnms <- list(datasetnames, algs)
crt_mat <- function() {
matrix(NA
, ncol = length(algs)
, nrow = nds
, dimnames = dmnms)
}
mn_meas <- crt_mat()
sd_meas <- crt_mat()
se_meas <- crt_mat()
mr_meas <- crt_mat()
N <- numeric(nds)
for (i in seq_along(datasetnames)) {
mns <- apply(analysis_in[[datasetnames[i]]]$comp_values, 2, mean)
mn_meas[i, names(mns)] <- mns
sds <- apply(analysis_in[[datasetnames[i]]]$comp_values, 2, sd)
sd_meas[i, names(sds)] <- sds
mrs <- apply(apply(sgn * analysis_in[[datasetnames[i]]]$comp_values, 1, rank), 1, mean)
mr_meas[i, names(mrs)] <- mrs
N[i] <- analysis_in[[datasetnames[i]]][["comp_frd.tt"]][["F.N"]]
}
dataset <- sub("_samp", "", sub("_small|_tiny", "", datasetnames))
mn_meas <- as.data.frame(mn_meas)
mn_meas$dataset <- dataset
mn_meas <- mn_meas %>% gather(algorithm, mean, -dataset)
se_meas <- sd_meas/sqrt(N)
se_meas <- as.data.frame(se_meas)
se_meas$dataset <- dataset
se_meas <- se_meas %>% gather(algorithm, st.err, -dataset)
mn_meas <- full_join(mn_meas, se_meas)
# mn_meas$alpha <- ifelse(mn_meas$algorithm == "CHIRPS"
#                         , "weight", "light")
g1 <- ggplot(data = mn_meas
, aes(x = dataset, y = mean
, ymin = I(mean-st.err)
, ymax = I(mean+st.err)
, colour = algorithm
, group = algorithm
, alpha = algorithm)) +
geom_line() +
geom_point() +
geom_errorbar(width = 0.2) +
colos +
alpas +
theme_bw() +
theme(panel.grid.major = element_blank()
, panel.grid.minor = element_blank())
return(g1)
}
measures <- c("stability.tr.lapl.", "precision.tt.", "stability.tt.lapl.", "xcoverage.tt.", "rule.length")
measure <- "stability.tr.lapl."
CHIRPS_analysis <- get_CHIRPS_analysis(measure, sens_results)
for (ds in datasetnames) {
print(c(CHIRPS_analysis[[ds]][["top_mean_block"]]
, CHIRPS_analysis[[ds]][["top_ranksum_block"]])
)
}
measure <- "stability.tt."
CHIRPS_analysis <- get_CHIRPS_analysis(measure, sens_results)
tt_analysis <- get_comparative_analysis(measure, comp_results, CHIRPS_analysis)
tt_analysis$adult_small_samp$comp_raw
View(tt_analysis$adult_small_samp$comp_raw)
library(lattice)
library(latticeExtra)
library(gridExtra)
library(rpart)
library(rpart.plot)
library(e1071)
library(randomForest)
source("eye_candy_theme.R")
set.seed(10)
x1.1 <- rbeta(100, 0.2, 0.2) + rnorm(100, 0, 0.05)
# Theme for TC report
# a nice colour palette
library(lattice)
library(ggplot2)
library(vcd)
myPal <- c("#8DD3C7", "#B0A8B3", "#9FB5D6", "#9EC0FA", "#FB9077")
myPalDark <- c("#4D8377", "#504853", "#3F5576", "#3E40DA", "#AB2012")
myPalContrasts <- c(myPalDark[1], myPalDark[5], myPal[2], myPal[4]
,"#999999"
, myPal[1], myPal[5], myPalDark[2], myPalDark[4])
myPal.range <- colorRampPalette(c("#FFFFFF", myPal[3:1]))
myPal.rangeDark <- colorRampPalette(c("#FFFFFF", myPalDark[3:1]))
myPal.rangeDiv <- colorRampPalette(c(myPal[5], "#FFFFFF", myPal[4]))
# fourfold 6
myPalFourFold <- c(myPalContrasts[6], myPalContrasts[1]
, myPalContrasts[7], myPalContrasts[4]
, myPalContrasts[2], myPalContrasts[9])
# applied to lattice
MyLatticeFont <- list(font = 1, fontsize = 12, col = myPalDark[2])
MyStripFont <- list(font = 1, cex = 0.8, col = myPalDark[2])
MyLatticeScale = list(tck = c(0.25, 0))
MyLatticeTheme <- list(
par.main.text = MyLatticeFont
, par.xlab.text = MyLatticeFont
, par.ylab.text = MyLatticeFont
, axis.text = MyLatticeFont
, add.text = MyLatticeFont
, fontsize = list(text = 11, points = 7)
, plot.symbol = list(col = myPalDark[5], pch = 19, alpha = 0.5, cex = 0.75)
, box.umbrella = list(col = myPalDark[5], lty = 2, lwd = 1.25)
, box.rectangle = list(fill = myPal.range(100)[3], col = myPalDark[5], lwd = 1.5)
, box.dot = list(col = myPalDark[5], pch = 15, cex = 0.8, alpha = 0.5)
, superpose.line = list(col = myPalContrasts)
, superpose.symbol = list(col = myPalContrasts)
, axis.line = list(col = myPal[2])
, strip.background = list(col=myPal.range(100)[3])
, strip.shingle = list(col=myPal.range(100)[12])
, strip.border = list(col = myPal[2])
, regions = list(col = myPal.rangeDiv(100))
)
MyLatticeStrip = strip.custom(par.strip.text = MyLatticeFont)
# applied to ggplot2
myGgTheme <- theme(plot.title = element_text(colour = myPalDark[2], size = 10)
, axis.title = element_text(colour = myPalDark[2], size = 10)
, axis.text = element_text(colour = myPalDark[2], size = 10)
, legend.title = element_text(colour = myPalDark[2])
, legend.text = element_text(colour = myPalDark[2]))
myGgThemeSilentX <- theme(plot.title = element_text(colour = myPalDark[2], size = 10)
, axis.title = element_text(colour = myPalDark[2], size = 10)
, axis.text.y = element_text(colour = myPalDark[2], size = 10)
, axis.text.x = element_blank()
, legend.title = element_text(colour = myPalDark[2])
, legend.text = element_text(colour = myPalDark[2]))
myGgThemeSilentY <- theme(plot.title = element_text(colour = myPalDark[2], size = 10)
, axis.title = element_text(colour = myPalDark[2], size = 10)
, axis.text.x = element_text(colour = myPalDark[2], size = 10)
, axis.text.y = element_blank()
, legend.title = element_text(colour = myPalDark[2])
, legend.text = element_text(colour = myPalDark[2]))
set.seed(10)
x1.1 <- rbeta(100, 0.2, 0.2) + rnorm(100, 0, 0.05)
x2.1 <-  cos(2 * pi * x1.1) * 2 + rnorm(100, 3, 0.5)
x1.2 <- (-x1.1 + 1.167) * 6
x1.1 <- x1.1 * 6 + 3.25
x2.2 <- -x2.1 + 9.5
x.1 <- cbind(x1.1, x2.1)
x.2 <- cbind(x1.2, x2.2)
xban <- rbind(x.1, x.2)
xban <- data.frame(xban)
names(xban) <- c("x1", "x2")
xban$y <- c(rep(1,100),rep(-1,100))
xban$y2 <- ifelse(xban$y == -1, 0, 1)
xban <- rbind(xban, data.frame(x1=c(6, 2, 8.2)
, x2=c(4, 4, 5)
, y=c(1, 1, -1)
, y2=c(1, 1, 0)))
pchx <- 1.5
xyplot(x2~x1, xban
, col = xban$y + 3
, pch = xban$y + 3
, cex = pchx)
svm.fit <- svm(y~x1+x2, data = xban, type = "C"
, kernel = "rad")
glm.fit <- glm(y2~x1+x2, data = xban, family = binomial())
rf.fit <- randomForest(factor(y2)~x1+x2, data = xban, ntree=1000)
tree.fit <- rpart(factor(y2)~x1+x2, data = xban
, method = "class"
, control = rpart.control(minsplit = 1
, maxcompete = 1))
db_plot <- function(predmat, titl) {
levelplot(y~x1*x2
, predmat
, main = titl
, xlim = c(-0.5, 10.5)
, ylim = c(-0.5, 10.5)
, colorkey = NULL
, par.settings = MyLatticeTheme
, alpha.regions = 0.5
, scales = MyLatticeScale
)}
library(e1071)
install.packages("e1071")
set.seed(10)
x1.1 <- rbeta(100, 0.2, 0.2) + rnorm(100, 0, 0.05)
x2.1 <-  cos(2 * pi * x1.1) * 2 + rnorm(100, 3, 0.5)
x1.2 <- (-x1.1 + 1.167) * 6
x1.1 <- x1.1 * 6 + 3.25
x2.2 <- -x2.1 + 9.5
x.1 <- cbind(x1.1, x2.1)
x.2 <- cbind(x1.2, x2.2)
xban <- rbind(x.1, x.2)
xban <- data.frame(xban)
names(xban) <- c("x1", "x2")
xban$y <- c(rep(1,100),rep(-1,100))
xban$y2 <- ifelse(xban$y == -1, 0, 1)
xban <- rbind(xban, data.frame(x1=c(6, 2, 8.2)
, x2=c(4, 4, 5)
, y=c(1, 1, -1)
, y2=c(1, 1, 0)))
pchx <- 1.5
xyplot(x2~x1, xban
, col = xban$y + 3
, pch = xban$y + 3
, cex = pchx)
svm.fit <- svm(y~x1+x2, data = xban, type = "C"
, kernel = "rad")
glm.fit <- glm(y2~x1+x2, data = xban, family = binomial())
library(e1071)
set.seed(10)
x1.1 <- rbeta(100, 0.2, 0.2) + rnorm(100, 0, 0.05)
x2.1 <-  cos(2 * pi * x1.1) * 2 + rnorm(100, 3, 0.5)
x1.2 <- (-x1.1 + 1.167) * 6
x1.1 <- x1.1 * 6 + 3.25
x2.2 <- -x2.1 + 9.5
x.1 <- cbind(x1.1, x2.1)
x.2 <- cbind(x1.2, x2.2)
xban <- rbind(x.1, x.2)
xban <- data.frame(xban)
names(xban) <- c("x1", "x2")
xban$y <- c(rep(1,100),rep(-1,100))
xban$y2 <- ifelse(xban$y == -1, 0, 1)
xban <- rbind(xban, data.frame(x1=c(6, 2, 8.2)
, x2=c(4, 4, 5)
, y=c(1, 1, -1)
, y2=c(1, 1, 0)))
pchx <- 1.5
xyplot(x2~x1, xban
, col = xban$y + 3
, pch = xban$y + 3
, cex = pchx)
svm.fit <- svm(y~x1+x2, data = xban, type = "C"
, kernel = "rad")
glm.fit <- glm(y2~x1+x2, data = xban, family = binomial())
rf.fit <- randomForest(factor(y2)~x1+x2, data = xban, ntree=1000)
tree.fit <- rpart(factor(y2)~x1+x2, data = xban
, method = "class"
, control = rpart.control(minsplit = 1
, maxcompete = 1))
db_plot <- function(predmat, titl) {
levelplot(y~x1*x2
, predmat
, main = titl
, xlim = c(-0.5, 10.5)
, ylim = c(-0.5, 10.5)
, colorkey = NULL
, par.settings = MyLatticeTheme
, alpha.regions = 0.5
, scales = MyLatticeScale
)}
decision_boundary_plot <- function(predmat
, training_set
, titl) {
plot_out <- db_plot(predmat, titl) +
as.layer(xyplot(x2~x1, training_set
, col = training_set$y + 3
, pch = training_set$y + 3
, cex = pchx)) +
as.layer(contourplot(y~x1*x2
, predmat
, labels = FALSE
, cuts = 1))
return(plot_out)
}
predpts <- 501
predmat <- expand.grid(x1 = seq(0, 10, length.out = predpts), x2 = seq(0, 10, length.out = predpts))
predmat$y <- factor(ifelse(predict(glm.fit, newdata = predmat, type = "response") > 0.5, 1, -1))
plot1 <- decision_boundary_plot(predmat, xban
, "Logistic Decision Boundary")
predmat$y <- factor(ifelse(as.numeric(as.vector(predict(tree.fit, newdata = predmat)[,2])) > 0.5, 1, -1))
plot2 <- decision_boundary_plot(predmat, xban
, "DT Decision Boundary")
predmat$y <- predict(svm.fit, newdata = predmat)
plot3 <- decision_boundary_plot(predmat, xban
, "SVM Decision Boundary")
predmat$y <- factor(ifelse(as.numeric(as.vector(predict(rf.fit, newdata = predmat))) > 0.5, 1, -1))
plot4 <- decision_boundary_plot(predmat, xban
, "RF Decision Boundary")
png(file = "C:\\Users\\Crutt\\OneDrive\\Documents\\PhD\\logdt_bound.png"
, width = 2160, height = 1440)
dev.off()
grid.arrange(plot1, plot2, ncol = 2)
